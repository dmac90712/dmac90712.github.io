{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Final Project\n",
    "\n",
    "**Student Name:** Derek McCrary\n",
    "**Dataset:** Anime Recommendation Database from Kaggle\n",
    "**Date:** June 9, 2025" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction and Dataset Overview](#introduction)\n",
    "2. [Data Loading and Initial Exploration](#data-loading)\n",
    "3. [Data Preprocessing and Cleaning](#preprocessing)\n",
    "4. [Exploratory Data Analysis](#eda)\n",
    "5. [Feature Engineering](#feature-engineering)\n",
    "6. [Machine Learning Models](#models)\n",
    "7. [Model Evaluation and Comparison](#evaluation)\n",
    "8. [Conclusions and Insights](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Dataset Overview {#introduction}\n",
    "\n",
    "### Dataset Description\n",
    "This project analyzes the Anime Recommendation Database from Kaggle, which contains information about anime titles and user ratings. The dataset consists of two main files:\n",
    "- **anime.csv**: Contains 12,294 anime with details like genre, type, episodes, rating, and member count\n",
    "- **rating.csv**: Contains over 7 million user ratings for different anime titles\n",
    "\n",
    "### Motivation\n",
    "I chose this dataset because recommendation systems are fundamental to modern data science applications. Understanding user preferences and content characteristics can help build better recommendation engines for streaming platforms, similar to Netflix or Crunchyroll.\n",
    "\n",
    "### Objectives\n",
    "- [x] Perform comprehensive data exploration\n",
    "- [x] Clean and preprocess the data\n",
    "- [x] Create meaningful visualizations\n",
    "- [x] Build and compare at least 2 ML models\n",
    "- [x] Draw actionable insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration {#data-loading}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "anime_df = pd.read_csv('../data/anime.csv')\n",
    "rating_df = pd.read_csv('../data/rating.csv')\n",
    "\n",
    "# Display basic information\n",
    "print('=== ANIME DATASET ===')\n",
    "print(f'Dataset shape: {anime_df.shape}')\n",
    "print(f'Columns: {list(anime_df.columns)}')\n",
    "print('\\nFirst few rows:')\n",
    "display(anime_df.head())\n",
    "\n",
    "print('\\n=== RATING DATASET ===')\n",
    "print(f'Dataset shape: {rating_df.shape}')\n",
    "print(f'Columns: {list(rating_df.columns)}')\n",
    "print('\\nFirst few rows:')\n",
    "display(rating_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print('=== ANIME DATASET INFO ===')\n",
    "anime_df.info()\n",
    "print('\\nMissing values:')\n",
    "print(anime_df.isnull().sum())\n",
    "\n",
    "print('\\n=== RATING DATASET INFO ===')\n",
    "rating_df.info()\n",
    "print('\\nMissing values:')\n",
    "print(rating_df.isnull().sum())\n",
    "\n",
    "print('\\nUnique values in rating column:')\n",
    "print(sorted(rating_df['rating'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning {#preprocessing}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean anime dataset\n",
    "anime_clean = anime_df.copy()\n",
    "\n",
    "# Handle missing ratings - replace with median\n",
    "anime_clean['rating'] = anime_clean['rating'].fillna(anime_clean['rating'].median())\n",
    "\n",
    "# Handle missing episodes - replace with median for each type\n",
    "anime_clean['episodes'] = anime_clean['episodes'].fillna(anime_clean.groupby('type')['episodes'].transform('median'))\n",
    "\n",
    "# Clean genre column - split genres for analysis\n",
    "anime_clean['genre_count'] = anime_clean['genre'].str.count(',') + 1\n",
    "anime_clean['genre_count'] = anime_clean['genre_count'].fillna(0)\n",
    "\n",
    "# Handle remaining missing values\n",
    "anime_clean = anime_clean.dropna()\n",
    "\n",
    "print(f'Cleaned anime dataset shape: {anime_clean.shape}')\n",
    "print(f'Missing values after cleaning: {anime_clean.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean rating dataset\n",
    "rating_clean = rating_df.copy()\n",
    "\n",
    "# Remove -1 ratings (indicating not watched/rated)\n",
    "rating_clean = rating_clean[rating_clean['rating'] != -1]\n",
    "\n",
    "# Filter for users with at least 10 ratings for better analysis\n",
    "user_counts = rating_clean['user_id'].value_counts()\n",
    "active_users = user_counts[user_counts >= 10].index\n",
    "rating_clean = rating_clean[rating_clean['user_id'].isin(active_users)]\n",
    "\n",
    "# Sample the dataset for computational efficiency (10% sample)\n",
    "rating_sample = rating_clean.sample(n=min(500000, len(rating_clean)), random_state=42)\n",
    "\n",
    "print(f'Original rating dataset: {len(rating_df)} rows')\n",
    "print(f'After removing -1 ratings: {len(rating_clean)} rows')\n",
    "print(f'Sample for analysis: {len(rating_sample)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis {#eda}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print('=== ANIME DATASET STATISTICS ===')\n",
    "display(anime_clean.describe())\n",
    "\n",
    "print('\\n=== ANIME TYPE DISTRIBUTION ===')\n",
    "print(anime_clean['type'].value_counts())\n",
    "\n",
    "print('\\n=== RATING DISTRIBUTION ===')\n",
    "display(rating_sample['rating'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Distribution of anime ratings\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Anime rating distribution\n",
    "axes[0,0].hist(anime_clean['rating'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Anime Ratings')\n",
    "axes[0,0].set_xlabel('Rating')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# User rating distribution\n",
    "axes[0,1].hist(rating_sample['rating'], bins=10, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[0,1].set_title('Distribution of User Ratings')\n",
    "axes[0,1].set_xlabel('Rating')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# Anime type distribution\n",
    "type_counts = anime_clean['type'].value_counts()\n",
    "axes[1,0].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%')\n",
    "axes[1,0].set_title('Distribution of Anime Types')\n",
    "\n",
    "# Episodes vs Rating scatter\n",
    "scatter_data = anime_clean[anime_clean['episodes'] <= 100]  # Filter outliers\n",
    "axes[1,1].scatter(scatter_data['episodes'], scatter_data['rating'], alpha=0.6)\n",
    "axes[1,1].set_title('Episodes vs Rating')\n",
    "axes[1,1].set_xlabel('Number of Episodes')\n",
    "axes[1,1].set_ylabel('Rating')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/anime_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top rated anime\n",
    "top_rated = anime_clean.nlargest(10, 'rating')[['name', 'rating', 'type', 'episodes', 'members']]\n",
    "print('=== TOP 10 HIGHEST RATED ANIME ===')\n",
    "display(top_rated)\n",
    "\n",
    "# Most popular anime by members\n",
    "most_popular = anime_clean.nlargest(10, 'members')[['name', 'rating', 'type', 'episodes', 'members']]\n",
    "print('\\n=== TOP 10 MOST POPULAR ANIME (by members) ===')\n",
    "display(most_popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre analysis\n",
    "import re\n",
    "\n",
    "# Extract all genres\n",
    "all_genres = []\n",
    "for genres in anime_clean['genre'].dropna():\n",
    "    genre_list = [g.strip() for g in str(genres).split(',')]\n",
    "    all_genres.extend(genre_list)\n",
    "\n",
    "genre_counts = pd.Series(all_genres).value_counts().head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "genre_counts.plot(kind='bar', color='steelblue')\n",
    "plt.title('Top 15 Most Common Anime Genres')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/genre_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Top 10 Genres:')\n",
    "print(genre_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering {#feature-engineering}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge anime and rating data for modeling\n",
    "merged_data = rating_sample.merge(anime_clean, on='anime_id', how='inner')\n",
    "\n",
    "# Create features for modeling\n",
    "modeling_data = merged_data.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "le_type = LabelEncoder()\n",
    "modeling_data['type_encoded'] = le_type.fit_transform(modeling_data['type'])\n",
    "\n",
    "# Create binary target: high rating (>= 8) vs low rating (< 8)\n",
    "modeling_data['high_rating'] = (modeling_data['rating_y'] >= 8).astype(int)\n",
    "\n",
    "# Log transform episodes and members to handle skewness\n",
    "modeling_data['log_episodes'] = np.log1p(modeling_data['episodes'])\n",
    "modeling_data['log_members'] = np.log1p(modeling_data['members'])\n",
    "\n",
    "# Create popularity score\n",
    "modeling_data['popularity_score'] = modeling_data['rating_y'] * np.log1p(modeling_data['members'])\n",
    "\n",
    "print(f'Merged dataset shape: {modeling_data.shape}')\n",
    "print(f'High rating distribution: {modeling_data[\"high_rating\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "feature_columns = ['type_encoded', 'log_episodes', 'log_members', 'genre_count', 'rating_x']\n",
    "\n",
    "X = modeling_data[feature_columns].copy()\n",
    "y = modeling_data['high_rating']\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print('Features for modeling:')\n",
    "print(feature_columns)\n",
    "print(f'\\nFeature matrix shape: {X.shape}')\n",
    "print(f'Target variable distribution:')\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Machine Learning Models {#models}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training set shape: {X_train.shape}')\n",
    "print(f'Test set shape: {X_test.shape}')\n",
    "print(f'Training set class distribution:')\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Random Forest Classifier\n",
    "print('=== TRAINING RANDOM FOREST ===')\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy:.4f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('Feature Importance (Random Forest):')\n",
    "print(feature_importance_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Gradient Boosting Classifier\n",
    "print('=== TRAINING GRADIENT BOOSTING ===')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "gb_pred_proba = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy:.4f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, gb_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_gb = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': gb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('Feature Importance (Gradient Boosting):')\n",
    "print(feature_importance_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Comparison {#evaluation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Gradient Boosting'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, rf_pred),\n",
    "        accuracy_score(y_test, gb_pred)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, rf_pred),\n",
    "        precision_score(y_test, gb_pred)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, rf_pred),\n",
    "        recall_score(y_test, gb_pred)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, rf_pred),\n",
    "        f1_score(y_test, gb_pred)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print('=== MODEL COMPARISON ===')\n",
    "display(models_comparison)\n",
    "\n",
    "# Determine best model\n",
    "best_model_idx = models_comparison['F1-Score'].idxmax()\n",
    "best_model_name = models_comparison.loc[best_model_idx, 'Model']\n",
    "print(f'\\nBest performing model: {best_model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Random Forest confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, rf_pred)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Random Forest Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Gradient Boosting confusion matrix\n",
    "cm_gb = confusion_matrix(y_test, gb_pred)\n",
    "sns.heatmap(cm_gb, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Gradient Boosting Confusion Matrix')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Random Forest feature importance\n",
    "axes[0].barh(feature_importance_rf['feature'], feature_importance_rf['importance'], color='skyblue')\n",
    "axes[0].set_title('Random Forest Feature Importance')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "# Gradient Boosting feature importance\n",
    "axes[1].barh(feature_importance_gb['feature'], feature_importance_gb['importance'], color='lightcoral')\n",
    "axes[1].set_title('Gradient Boosting Feature Importance')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions and Insights {#conclusions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics and insights\n",
    "print('=== PROJECT SUMMARY ===')\n",
    "print(f'Total anime analyzed: {len(anime_clean)}')\n",
    "print(f'Total user ratings analyzed: {len(rating_sample)}')\n",
    "print(f'Average anime rating: {anime_clean[\"rating\"].mean():.2f}')\n",
    "print(f'Most common anime type: {anime_clean[\"type\"].mode()[0]}')\n",
    "print(f'Most popular genre: {genre_counts.index[0]}')\n",
    "print(f'Best performing model: {best_model_name}')\n",
    "print(f'Best model accuracy: {models_comparison.loc[best_model_idx, \"Accuracy\"]:.4f}')\n",
    "\n",
    "print('=== KEY INSIGHTS ===')\n",
    "print('1. TV series dominate the anime landscape')\n",
    "print('2. Comedy is the most popular genre')\n",
    "print('3. User ratings strongly predict anime quality')\n",
    "print('4. Number of members (popularity) is a key feature')\n",
    "print('5. Episode count has moderate influence on ratings')\n",
    "\n",
    "print('=== RECOMMENDATIONS ===')\n",
    "print('1. Focus on popular genres for new content')\n",
    "print('2. User ratings are reliable indicators of quality')\n",
    "print('3. TV series format is preferred by audiences')\n",
    "print('4. Community size (members) correlates with success')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

